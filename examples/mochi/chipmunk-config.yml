num_model_invocations_per_inference_step: 2

patchify:
  is_enabled: false

attn:
  is_enabled: true
  top_keys: 0.15
  random_keys: 0.01
  # Number of local voxels to use for static local attention
  local_voxels: 0
  local_1d_window: 0
  first_n_dense_layers: 2
  recompute_mask: true
  should_compress_indices: true
  full_attn_from_3d_tail: false
  full_attn_to_3d_tail: false

  # If schedule is not None, will override full_step_every
  full_step_schedule: !!set
    ? 0
    ? 1
    ? 15
    ? 30
    ? 45
    ? 60
  # full_step_every: 10

  # Do not change below this line -- kernel-specific business
  pad_qkv_before_kernel: true
  counts_multiple_of: 128

offloading:
  attn.out_cache: true
  attn.indices: true

step_caching:
  is_enabled: false
  # Feel free to play with this -- it's pretty stable across different schedules!
  skip_step_schedule: !!set
    ? 7
    ? 11
    ? 13
    ? 14
    ? 15
    ? 17
    ? 18
    ? 19
    ? 21
    ? 22
    ? 23
    ? 25
    ? 26
    ? 27
    ? 29
    ? 31
    ? 33
    ? 34
    ? 35
    ? 37
    ? 38
    ? 39
    ? 41
    ? 42
    ? 43
